### YamlMime:PowershellCmdlet
summary: |-
  Uploads a local file or directory to a Data Lake Store.
module: Az.DataLakeStore
notes: ""
inputs:
- name: <xref href="System.String" data-throw-if-not-resolved="False" />
  description: ""
- name: <xref href="Microsoft.Azure.Commands.DataLakeStore.Models.DataLakeStorePathInstance" data-throw-if-not-resolved="False" />
  description: ""
- name: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  description: ""
- name: <xref href="System.Int32" data-throw-if-not-resolved="False" />
  description: ""
- name: <xref href="Microsoft.Azure.Commands.DataLakeStore.Models.LogLevel" data-throw-if-not-resolved="False" />
  description: ""
outputs:
- name: <xref href="System.String" data-throw-if-not-resolved="False" />
  description: ""
links:
- text: Get-AzDataLakeStoreItem
  href: ./Get-AzDataLakeStoreItem.yml
- text: Export-AzDataLakeStoreItem
  href: ./Export-AzDataLakeStoreItem.yml
- text: Join-AzDataLakeStoreItem
  href: ./Join-AzDataLakeStoreItem.yml
- text: Move-AzDataLakeStoreItem
  href: ./Move-AzDataLakeStoreItem.yml
- text: New-AzDataLakeStoreItem
  href: ./New-AzDataLakeStoreItem.yml
- text: Remove-AzDataLakeStoreItem
  href: ./Remove-AzDataLakeStoreItem.yml
- text: Test-AzDataLakeStoreItem
  href: ./Test-AzDataLakeStoreItem.yml
syntaxes:
- >-
  Import-AzDataLakeStoreItem [-Account] <String> [-Path] <String> [-Destination] <DataLakeStorePathInstance>

   [-Recurse] [-Resume] [-ForceBinary] [-Force] [-Concurrency <Int32>] [-DefaultProfile <IAzureContextContainer>]

   [-WhatIf] [-Confirm] [<CommonParameters>]
- >-
  Import-AzDataLakeStoreItem [-Account] <String> [-Path] <String> [-Destination] <DataLakeStorePathInstance>

   [-Recurse] [-Resume] [-ForceBinary] [-Force] [-Concurrency <Int32>] [-DiagnosticLogLevel <LogLevel>]

   -DiagnosticLogPath <String> [-DefaultProfile <IAzureContextContainer>] [-WhatIf] [-Confirm]

   [<CommonParameters>]
examples:
- title: 'Example 1: Upload a file'
  code: |-
    PS C:\>Import-AzDataLakeStoreItem -AccountName "ContosoADL" -Path "C:\SrcFile.csv" -Destination "/MyFiles/File.csv" -Concurrency 4
  description: |-
    This command uploads the file SrcFile.csv and adds it to the MyFiles folder in the Data Lake Store as File.csv with a concurrency of 4.
  summary: ""
parameters:
- type: <xref href="System.String" data-throw-if-not-resolved="False" />
  name: Account
  isRequired: true
  description: |+
    Specifies the name of the Data Lake Store account.

  defaultValue: None
  pipelineInput: true
  position: "0"
  aliases: AccountName
  parameterValueGroup: ""
- type: <xref href="System.Int32" data-throw-if-not-resolved="False" />
  name: Concurrency
  description: |+
    Indicates the number of files or chunks to upload in parallel. Default will be computed as a best effort based on system specifications.

  defaultValue: None
  pipelineInput: true
  position: Named
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: Confirm
  description: |+
    Prompts you for confirmation before running the cmdlet.

  defaultValue: "False"
  position: Named
  aliases: cf
  parameterValueGroup: ""
- type: <xref href="Microsoft.Azure.Commands.Common.Authentication.Abstractions.Core.IAzureContextContainer" data-throw-if-not-resolved="False" />
  name: DefaultProfile
  description: |+
    The credentials, account, tenant, and subscription used for communication with azure.

  defaultValue: None
  position: Named
  aliases: AzContext, AzureRmContext, AzureCredential
  parameterValueGroup: ""
- type: <xref href="Microsoft.Azure.Commands.DataLakeStore.Models.DataLakeStorePathInstance" data-throw-if-not-resolved="False" />
  name: Destination
  isRequired: true
  description: |+
    Specifies the Data Lake Store path to which to upload a file or folder, starting with the root directory (/).

  defaultValue: None
  pipelineInput: true
  position: "2"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="Microsoft.Azure.Commands.DataLakeStore.Models.LogLevel" data-throw-if-not-resolved="False" />
  name: DiagnosticLogLevel
  description: |+
    Optionally indicates the diagnostic log level to use to record events during the file or folder import. Default is Error.

  defaultValue: Error
  pipelineInput: true
  position: Named
  aliases: ""
  parameterValueGroup: Debug, Information, Error, None
- type: <xref href="System.String" data-throw-if-not-resolved="False" />
  name: DiagnosticLogPath
  isRequired: true
  description: |+
    Specifies the path for the diagnostic log to record events to during the file or folder import.

  defaultValue: None
  pipelineInput: true
  position: Named
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: Force
  description: |+
    Indicates that this operation can overwrite the destination file if it already exists.

  defaultValue: None
  pipelineInput: true
  position: "8"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: ForceBinary
  description: |+
    Indicates that the file(s) being copied should be copied with no concern for new line preservation across appends.

  defaultValue: None
  pipelineInput: true
  position: "5"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.String" data-throw-if-not-resolved="False" />
  name: Path
  isRequired: true
  description: |+
    Specifies the local path of the file or folder to upload.

  defaultValue: None
  pipelineInput: true
  position: "1"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: Recurse
  description: |+
    Indicates that this operation should upload all items in all subfolders.

  defaultValue: None
  pipelineInput: true
  position: "3"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: Resume
  description: |+
    Indicates that the file(s) being copied are a continuation of a previous upload. This will cause the system to attempt to resume from the last file that was not fully uploaded.

  defaultValue: None
  pipelineInput: true
  position: "4"
  aliases: ""
  parameterValueGroup: ""
- type: <xref href="System.Management.Automation.SwitchParameter" data-throw-if-not-resolved="False" />
  name: WhatIf
  description: |+
    Shows what would happen if the cmdlet runs.
    The cmdlet is not run.

  defaultValue: "False"
  position: Named
  aliases: wi
  parameterValueGroup: ""
uid: Az.DataLakeStore.Import-AzDataLakeStoreItem
name: Import-AzDataLakeStoreItem
description: |-
  The **Import-AzDataLakeStoreItem** cmdlet uploads a local file or directory to a Data Lake Store.
metadata:
  external help file: Microsoft.Azure.PowerShell.Cmdlets.DataLakeStore.dll-Help.xml
  Module Name: Az.DataLakeStore
  ms.assetid: 90630395-8747-4446-A879-323274811956
  online version: https://docs.microsoft.com/en-us/powershell/module/az.datalakestore/import-azdatalakestoreitem
  schema: 2.0.0
  content_git_url: https://github.com/Azure/azure-powershell/blob/master/src/DataLakeStore/DataLakeStore/help/Import-AzDataLakeStoreItem.md
  original_content_git_url: https://github.com/Azure/azure-powershell/blob/master/src/DataLakeStore/DataLakeStore/help/Import-AzDataLakeStoreItem.md
